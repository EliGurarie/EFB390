<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>How to model just about anything (but especially habitat)</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Elie Gurarie" />
    <meta name="date" content="2023-09-28" />
    <script src="Lecture_Modeling_files/header-attrs-2.21/header-attrs.js"></script>
    <link href="Lecture_Modeling_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="Lecture_Modeling_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="Lecture_Modeling_files/fabric-4.3.1/fabric.min.js"></script>
    <link href="Lecture_Modeling_files/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="Lecture_Modeling_files/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="Lecture_Modeling_files/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="Lecture_Modeling_files/tile-view-0.2.6/tile-view.js"></script>
    <script src="Lecture_Modeling_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="Lecture_Modeling_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="mycss.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, white, title-slide

.title[
# How to model just about anything<br>(but especially habitat)
]
.subtitle[
## EFB 390: Wildlife Ecology and Management
]
.author[
### Dr. Elie Gurarie
]
.date[
### September 28, 2023
]

---


&lt;!-- https://bookdown.org/yihui/rmarkdown/xaringan-format.html --&gt;













## Super fast primer on statistical modeling


Everything you need to know to do 95% of all wildlife modeling in less than an hour and **FOUR** (or **FIVE**) easy steps!!

.pull-left.large[

**I.** Linear modeling

**II.** Multivariate modeling

**III.** Model selection 
]

.pull-right.large[

**IV.** Generalized linear modeling 
  - Poisson; Binomial

**V.** Prediction
]

---


.pull-left-70[
# **Step I:** Linear modeling 

... is a very general method to quantifying relationships among variables.  

.pull-left[
![](Lecture_Modeling_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;
]
.pull-right[

`\(X_i\)` - is called:
- covariate
- independent variable
- explanatory variable

`\(Y_i\)` - is the property we are interested in modeling:
- response variable
- dependent variable

.small[Note: There actually can be interest in wildlife studies to have models for **length** and **weight**, since **length** is easy to measure (e.g. from drones), but **weight** tells us more about physical condition and energetics.]
]
]


.pull-right-30[
![](images/pups_small.jpg)

Steller sea lion (*Eumatopias jubatus*) pups.  

]



---

# Linear Models
.pull-left[
#### Deterministic:

`$$Y_i = a + bX_i$$`

`\(a\)` - intercept; `\(b\)` - slope
]

.pull-right[
#### Probabilistic:

`$$Y_i = \alpha + \beta X_i + \epsilon_i$$`

`\(\alpha\)` - intercept; `\(\beta\)` - slope; `\(\epsilon\)` - **randomness!**: `\(\epsilon_i \sim {\cal N}(0, \sigma)\)`
]


.pull-left[
![](Lecture_Modeling_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]


.pull-right[
![](Lecture_Modeling_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
]

---

# Fitting linear models is very easy in ![](images/R.png)!

.pull-left[

**Point Estimate**

This command fits a model:
.small[

```r
lm(Weight ~ Length, data = pups)
```

```
## 
## Call:
## lm(formula = Weight ~ Length, data = pups)
## 
## Coefficients:
## (Intercept)       Length  
##    -49.1422       0.7535
```
]

So for **each 1 cm** of length, add another **754 grams**, i.e. `\(\widehat{\beta} = 0.754\)`


]

.pull-right[

```r
plot(Weight ~ Length, data = pups)
abline(my_model)
```

![](Lecture_Modeling_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

The `abline` puts a line, with intercept `a` and slope `b` onto a figure.
]


---


.pull-left-60[

# Statistical inference

**Statistical inference** is the *science / art* of observings *something* from a **portion of a population** and making statements about the **entire population**.  

In practice - this is done by taking  **data** and **estimating  parameters** of a **model**.  (This is also called *fitting* a model). 

Two related goals: 

1. obtaining a **point estimate** and a **confidence interval** (precision) of the parameter estimate. 
2. Assessing whether particular (combinations of) factors, i.e. **models**, provide any **explanatory power**. 

This is (almost always) done using **Maximum Likelihood Estimation**, i.e. an algorithm searches through possible values of the parameters that make the model **MOST LIKELY** (have the highest probability) given the data. 
]

.pull-right-40[
![](images/SSL_withpup.jpg)

.small[Another gratuitous sea lion picture.]
]


---


# All models have these pieces:

`$$\Huge Y = f({\bf X} | \bf{\Theta})$$`
 - **Y** - response | dependent variable.  The thing we want to model / predict / understand. The **effect** (maybe). 
 
- **X** - predictor(s) | independent variable(s) | covariate(s).  The thing(s) that "explain(s)" **Y**. The **cause** (maybe). 

- **f** - the model structure.  This includes: some **deterministic functional form** form (*linear? periodic? polynomial? exponential?*) AND some **probabilistic assumptions**, i.e. a way to characterize the variability / randomness / unpredictability of the process. 

- `\(\bf \Theta\)` - the parameters of the model.  There are usually some parameters associated with the **predictors**, and some associated with the **random bit**. 

---

# Goals (Art / Science)  of Modeling

`$$\Huge Y = f({\bf X} | \bf{\Theta})$$`

.pull-left[

### 1. Model fitting

.darkred[
What are the **best** `\(\bf \Theta\)` values given `\(f, {\bf X}, Y\)`?
]

**Fitting the model** = **estimating the parameters**.  

Usually according to some criterion (almost always **Maximum Likelihood**.

]

--



.pull-right[
### 2. Model selection

.darkred[

What are the **best** of a set of models `\(f_1\)`, `\(f_2\)`, `\(f_3\)` given `\(\bf X\)` and `\(Y\)`?

]

Different models *usually* vary by what particular variables go into **X**, but can also vary by **functional form** and **distribution assumptions**

Use some **Criterion** (e.g. AIC) to "select" the best model, which balances **how many parameters you estimated**  verses **how good the fit is**. 

]




---

# Whoa!   What is "Maximum Likelihood"!?


.pull-left[

### Oakie

![](images/likelihoods/blackmorph.jpg) 

]

.pull-right[

### Orange

![](images/likelihoods/greysquirrels.jpg) 

]

.red.center.large[**Q:** What is the "best model" for squirrel morph distribution?]


---



`$$\Huge Y = f({\bf X} | \bf{\Theta})$$`

.pull-left[
#### Linear model

Two ways to write the same thing: 

`$$Y_i = \alpha + \beta X_i + \epsilon_i$$`
`$$Y_i \sim {\cal N}(\alpha + \beta X_i,  \sigma)$$`

![](Lecture_Modeling_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
]


.pull-right.large[

- Response `\(Y\)` - Weight

- Predictor `\(X\)` - Length

- Parameters `\(\Theta\)`:  `\(\alpha\)`;  `\(\beta\)`; `\(\sigma\)`

- Function `\(f()\)`: Normal distribution `\({\cal N()}\)`



]

---

.pull-left-60[

## Statistical output


`$$\large Y_i \sim {\cal N}(\alpha + \beta X_i,  \sigma)$$`

&lt;font size="4"&gt;&lt;pre&gt;

```
## 
## Call:
## lm(formula = Weight ~ Length, data = pups %&gt;% subset(Island == 
##     "Raykoke"))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.498 -1.718  0.023  1.764  7.276 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -49.14222    5.75796  -8.535 1.81e-13 ***
## Length        0.75345    0.05193  14.510  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.761 on 98 degrees of freedom
## Multiple R-squared:  0.6824,	Adjusted R-squared:  0.6791 
## F-statistic: 210.5 on 1 and 98 DF,  p-value: &lt; 2.2e-16
```
&lt;/pre&gt;&lt;/font&gt;
]

--
.pull-right-40[

### 1. Point estimates and confidence intervals
.red.center[
**Intercept** ( `\(\alpha\)` ):  `\(-49.14 \pm 11.5\)`

**Slope** ( `\(\beta\)` ):  `\(0.75 \pm 0.104\)`
]

### 2. Is the model a good one? 

*p*-values are very very small, in particular for **slope**

Proportion of variance explained is high:

.blue.large[$$R^2 = 0.68$$]

]

---

### Models and Hypotheses

&gt; .large[**Every *p*-value is a Hypothesis test.**]
&gt;

.center[
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; t value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Pr(&amp;gt;|t|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -49.142 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.758 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -8.535 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Length &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.753 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.052 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.510 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]


.large[
- First hypothesis test: `\(H_0\)` .darkred[intercept = 0]
- Second hypothesis: `\(H_0\)` .blue[slope = 0]

Both null-hypotheses strongly rejected. 
]


---

## But other variables might influence pup size





.pull-left-30[
Lots of competing models with different **main** and **interaction** effects. 
]

.pull-right-70[
![](Lecture_Modeling_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;
]

---

## Linear modeling with a discrete factor

.center[
`\(Y_{ij} = \alpha + \beta_i + \epsilon_{ij}\)`
]

`\(i\)` is the index of sex (*Male* or *Female*), so there are two "Sex effects" - `\(\beta_1\)` and `\(\beta_2\)` representing the effect of the sex group; *j* is the index of the individual within each sex group *i*. 

.pull-left-50[


![](Lecture_Modeling_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;
]

.pull-right[


```r
lm(Weight ~ Sex, data = pups)
```


.footnotesize[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.151 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.317 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 95.119 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; &lt;2e-16 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; SexMale &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6.149 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.429 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.337 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; &lt;2e-16 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

*Intercept* here means mean **female** weight. 

Note - this is very similar to a *t*-test comparing two means (baby stats). 

]



---

## Linear modeling with multiple factors

Very easy to extend this to more complicated models!

.pull-left-50[


![](Lecture_Modeling_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]

.pull-right[
.center.large.green[
`\(Y_{ijk} = \alpha + \beta_i \, \text{Island}_{ijk} + \gamma_j \, \text{Sex}_{ijk} + \epsilon_{ijk}\)`
]


```r
lm(Weight ~ Island + Sex, data = pups)
```



.footnotesize[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31.04 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.54 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 57.62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; &lt;1e-16 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; IslandChirpoev &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.34 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; IslandLovushki &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.84 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; IslandRaykoke &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.21 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.83 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; IslandSrednova &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.24 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.03 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; SexMale &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.47 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1e-16 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]
]


---

## Analysis of Variance  (ANOVA)

Is a technique for seeing which effect in a model is **significant**.  Each row tests a **hypothesis** that the effect coefficients are non-zero.  

.pull-left-60[

In this model, we include an **interaction**, asking: 
"*Do different Islands have different patterns among Sexes? (and vice versa)*"

.center[`lm(Weight ~ Island * Sex, data = pups)`]

.content-box-blue[

.small[&lt;pre&gt;Analysis of Variance Table

Response: Weight
            Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
Island       4   443.3   110.8   5.0114 0.0005763 ***
Sex          1  4623.9  4623.9 209.0758 &lt; 2.2e-16 ***
Island:Sex   4    71.4    17.9   0.8075 0.5207439    
Residuals  488 10792.6    22.1                       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
&lt;/pre&gt;]
]

.blue[**Non-significant interaction term**]
]

.pull-right-40[
### Interpretation: 
- Differences between SEXES very significant  (.red[very very small p-value])
- Differences among ISLANDS very significant (.red[small p-value])
- SEX differences among ISLANDS consistent (.blue[large **interaction** *p*-value])
- ISLANDS differences between SEXES consistent (.blue[large **interaction** *p*-value])
]


---

## Combining **continuous** and **categorical** variables

.pull-left[

**Exploratory plot**

.center[
&lt;img src="Lecture_Modeling_files/figure-html/unnamed-chunk-22-1.png" width="90%" /&gt;
]
It looks like, maybe, there are different body proportions for .blue[**MALES**] and .red[**FEMALES**]. 
]

--

.pull-right[


### **ANOVA** table confirms our suspicion!


.content-box-blue[
.footnotesize[&lt;pre&gt;Analysis of Variance Table

Response: Weight
            Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
Length       1 12413.8 12413.8 1957.969 &lt; 2.2e-16 ***
Sex          1   257.3   257.3   40.582 4.321e-10 ***
Length:Sex   1   128.1   128.1   20.208 8.662e-06 ***
Residuals  494  3132.0     6.3                       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
&lt;/pre&gt;]
]

.large.darkred[Highly significant **interaction** term.]

]

---

.pull-left[
# **Step III:** Model Selection

ANOVA is helpful for "nested" models, where each one is a subset of another more complex one.  For comparing a **set of competing,non-nested** models, we use . 

.footnotesize[

### `\(\Delta\)`AIC table

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;  &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; k &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; R2 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; logLik &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; dAIC &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1569.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3143.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 835.8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Island &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.028 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1562.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3137.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 829.7 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Sex &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.293 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1483.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2972.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 665.1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Length &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.779 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1193.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2392.8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 85.5 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Length + Sex &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.795 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1174.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2357.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49.7 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Length * Sex &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.803 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1164.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2339.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31.7 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Length + Sex + Island &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.811 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1155.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2325.9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; M7 &lt;/td&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; Length * Sex + Island &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 0.818 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; -1144.6 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 2307.3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 0.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Length * Sex * Island &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.824 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1137.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2316.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.8 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]
]

.pull-right[

**Degrees of freedom *k*:**

- Number of estimated parameters. Measure of *complexity*. 

**Coefficient of determination R&lt;sup&gt;2&lt;/sup&gt;:**  

- Percent variation explained. It ALWAYS increases the more complex the model.
- Is is always zero for the **NULL** model. 

**log-likelihood `\(\log({\cal L})\)`:**  

- Total probability score of model. It ALWAYS increases the more complex the model.

**Akaike Information Criterion:**  

- `\(AIC = -2 \log({\cal L}) + 2\,k\)`
- A measure of model quality. 
- Smaller is better It starts getting bigger if the model complexity gets too high. 
- .red[**The lowest AIC value is the "best" model.**] 
- (but within 2 `\(\Delta AIC\)` is pretty much equivalent to best)
]

---
background-image: url('images/AfricanUngulatesBiomass.png')
background-size: cover

## AIC in action: **What predicts ungulate body size?**

Quality (Nitrogen)? or Type (browse/grass)? 

---
background-image: url('images/GurarieSpringMigrations0.png')
background-size: cover

.pull-left-60[
&lt;video width="100%" controls="controls"&gt;
&lt;source src="https://terpconnect.umd.edu/~egurarie/research/ABoVE/springmigration/migrationanimation6.mp4"&gt;
&lt;/video&gt;
]

.pull-right-40[
## Caribou spring migrations

Remarkable temporal synchrony at a continental scale. 
]

---
background-image: url('images/GurarieSpringMigrations.png')
background-size: cover

## Could the synchrony be driven by global weather drivers?

.pull-right-70[
Pacific Decadal Oscillation, Arctic Oscillation, North Atlantic Oscillation:  determine whether the winter is wet &amp; snowy or dry &amp; cold. 
]

---
background-image: url('images/GurarieSpringMigrations2.png')
background-size: cover

## `\(\Delta\)`AIC Table 1: **Departure time** 

.pull-right[... driven by LARGE climate oscillations.]

---
background-image: url('images/GurarieSpringMigrations3.png')
background-size: cover

## `\(\Delta\)`AIC Table 2: **Arrival time** 

.pull-right[... completely independent of climate!]

---
class: small

.pull-left[
## ***Step IV:*** *Generalized* linear modeling

### Normal Model

.large[$$Y_i \sim {\cal Normal}(\alpha_0 + \beta_1 X_i, \sigma)$$]
Models continuous data with a "normal-like" distribution.

![](Lecture_Modeling_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;
]

--

.pull-right[
### Binomial model

.large[$$Y_i \sim {\cal Bernoulli}\left( \frac{\exp(\alpha + \beta X_i)}{1 + \exp(\alpha + \beta X_i)} \right)$$]

There's some *probability* of something happening that depends on the predictor `\(X\)`.  

**Bernoulli** just means the data are all 0 or 1. 

![](Lecture_Modeling_files/figure-html/unnamed-chunk-26-1.png)&lt;!-- --&gt;

This models **presence/absence**, **dead/alive**, **male/female** other response variables with **2** possible outcomes. 
]

---
background-image: url('images/SoleaSolea.png')
background-size: cover

### What factors predict occurence of *Solea solea* larvae?

Sampled in the estuary of the Tejo river in Portugal

- Lots of environmental factors in data

.pull-right-70[.footnotesize[
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; depth &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; temp &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; salinity &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; transp &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; gravel &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; large_sand &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; fine_sand &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; mud &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; presence &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.74 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.93 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71.18 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.94 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.99 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.43 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 87.63 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8.98 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.85 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 71.29 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 29 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.06 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.96 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 21.95 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 55.03 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.87 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 28.60 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.49 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 42.04 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 3.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 32 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 32.45 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.39 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.43 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50.72 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]]

---

# Presence of *Solea solea* against **salinity**

.pull-left-40[
![](Lecture_Modeling_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;
]

.pull-right-60[

Modeling is EXACTLY the same as **linear regression** except:
- `glm` - for **generalized** linear model (instead of `lm`)
- `family = 'binomial'` is the instruction to fit the logistic regression


`glm(presence ~ salinity, family ='binomial')`

&lt;font size = 4&gt;
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.661 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.902 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.951 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.003 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; salinity &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.130 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.035 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.716 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/font&gt; 

Clearly - *Solea solea* presence is very significantly *negatively* related to salinity.  
]


---
### Out of this model we can make predictions


&lt;img src="Lecture_Modeling_files/figure-html/unnamed-chunk-31-1.png" width="80%" /&gt;

---

.pull-left[

## `\(\Delta\)`AIC analysis - and coefficients



&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;  &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; k &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; logLik &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; dAIC &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; M9 &lt;/td&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; salinity + gravel &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; -33.2 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 72.5 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;font-weight: bold;color: darkblue !important;background-color: yellow !important;"&gt; 0.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; M2 &lt;/td&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; salinity &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; -34.3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 72.6 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 0.1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; M7 &lt;/td&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; temp + salinity &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; -34.0 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 74.0 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 1.5 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; M5 &lt;/td&gt;
   &lt;td style="text-align:left;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; depth + salinity &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; -34.1 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 74.3 &lt;/td&gt;
   &lt;td style="text-align:right;font-weight: bold;color: darkblue !important;background-color: lightgreen !important;"&gt; 1.8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M11 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; depth + temp + salinity &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -33.9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 75.8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M0 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; depth &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -38.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 80.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; depth + temp &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -38.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 81.9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; depth + gravel &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -38.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.5 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; depth + temp + gravel &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -37.8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 83.7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; temp &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -43.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 90.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; gravel &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -43.7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 91.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; M8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; temp + gravel &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -43.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 92.6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20.1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

.pull-right[
**Salinity** clearly among the more important covariates (in the top 4 models). 

![](Lecture_Modeling_files/figure-html/unnamed-chunk-34-1.png)&lt;!-- --&gt;

]



---
background-image: url("images/RSF_dAIC.png")
background-size: cover

## FLASHBACK: how the caribou Resource Selection Function was selected

---
## Poisson regression

.pull-left-30[

![](images/Poisson1.png)
![](images/Poisson4.png)
![](images/Poisson10.png)

]

.pull-right-70[

.large[$$Y_i \sim {\cal Poisson}\left(\lambda = \exp(\alpha + \beta X_i) \right)$$]

- We are **counting** something ... the data are between 0 and `\(\infty\)` 
- `\(\lambda\)` is a **density**;  **densities** vary across habitat types (covariate **X**). 

.center[&lt;img src='images/Moose2.png' width='70%'/&gt;]
]



---

## Field flags

.large[**Did flag densities vary with region?**]

.pull-left-40[

Approximate areas:

region | area
--|--
**North:** | 82 m&lt;sup&gt;2&lt;/sup&gt;
**South:** | 82 m&lt;sup&gt;2&lt;/sup&gt;
**Perimeter:** | 196 m&lt;sup&gt;2&lt;/sup&gt;
--|--
**Sampling square (hula hoop)** | 0.5 m&lt;sup&gt;2&lt;/sup&gt;
]
.pull-right-60[

![](images/court.png)]


---


.pull-left[

### Count data



Lots of 0's, some 1's, and just one 2 count.


```
##      Region
## Count North Perimeter South
##     0    15        12     9
##     1     1         1     6
##     2     0         0     1
```

![](Lecture_Modeling_files/figure-html/unnamed-chunk-36-1.png)&lt;!-- --&gt;
]

.pull-right[

### Fitting models

.large[
`glm(count ~ region, family = 'poisson')`

Exact same syntax as before, except the "family" is **Poisson.** 
]]

---


.pull-left[

### Count data



Lots of 0's, some 1's, and just one 2 count.


```
##      Region
## Count North Perimeter South
##     0    15        12     9
##     1     1         1     6
##     2     0         0     1
```

![](Lecture_Modeling_files/figure-html/unnamed-chunk-38-1.png)&lt;!-- --&gt;
]

.pull-right[

### Fitting models


&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; z value &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Pr(&amp;gt;|z|) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.773 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.773 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.006 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; RegionPerimeter &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.208 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.414 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.147 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.883 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; RegionSouth &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.079 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.061 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.961 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.050 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

The **intercept** here is "North", the *p*-values compare with North.  So **South** has - borderline - significantly more 

#### `\(\Delta AIC\)` table

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; df &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; AIC &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Null.model &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 53.47 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Region.model &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 49.15 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Model that includes **Region** has lower AIC

]


---

### Making predictions

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Region &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; area &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; fit &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; se.fit &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; l.hat &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; l.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; l.high &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; d.hat &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; d.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; d.high &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; N.hat &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; N.low &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; N.high &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; South &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.693 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.354 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.500 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.247 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.014 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.493 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.028 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 166.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; North &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.773 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.063 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.008 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.462 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.125 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.017 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.924 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 10.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 75.8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Perimeter &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 196 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.565 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.077 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.010 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.568 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.154 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.021 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.137 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 222.9 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.small[
- **fit** and **se.fit** are in the log scale, so they need to be transformed via `\(exp\)` to intensities `\(\lambda\)`. 

- `l.hat` is the Poisson intensity `\(\lambda\)` of the sampling square (**hula hoop**), which we turn into an actual density by dividing by its area **0.5 m&lt;sup&gt;2&lt;/sup&gt;**.

- `d.hat` (and `d.low` and `d.high`) are the density estimates &amp; confidence intervals, which we then turn into our numerical predictions by multiplying by area. 
]

### Total estimate

.large.green[ 
`$$\widehat{N} = 122.4 \, (95\%\, \text{C.I.}: 71.4 - 173.4)$$`
]

**pretty darned good!**  The true values were 92 total [58 S, 29 N, 13 perimeter]




---
background-image:  url('images/LEGO.jpg')
background-size: cover



.content-box-blue[

## .darkred[**Take-aways on (linear, statistical) modeling**]

1. **Linear modeling** separates **patterns** (the model) from "**randomness**" (unexplained variation).

2. We structure our models to have a **response variable** and one or more **predictors** or **covariates**. 

3. Depending on the reponse variable, a different **family** is chosen:
  - if **continuous** and symmetric: **Normal** family
  - if two values (presence/absence, dead/alive): **Binomial** family
  - if count data: **Poisson** family. 

3. An important task is **Model selection**, identifying which model is "best" 
  - Best means *"explains the most variation without overfitting"* 
  - Very common criterion is **AIC.**
  
4. Once a model is "selected", we can:
  - analyze the results by seeing the **effect sizes** (magnitude of coefficients, aka *slopes*) and **directions** (signs of coefficients) 
  - make **inferential predictions** by "spreading" our model over a larger landscape.
  
6. **Well over 90% of habitat modeling is done this way!**
  
]




---

# extra slides

---

# Some comments on linear models


$$ Y_i \sim \alpha + \beta X_i + \epsilon_i$$

1. `\(\epsilon_i\)` is **unexplained variation** or **residual variance**.  It is often POORLY/WRONGLY referred to as "**error**".  It is a **random variable**, NOT a **parameter**

--

2. A **better**, more sophisticated way to think of this model is not to focus on isolating the residual variance, but that the whole process is a random variable: `$$Y_i \sim {\cal N}(\alpha + \beta X_i, \sigma)$$` This is better because: (a) the three parameters ( `\(\alpha, \beta, \sigma\)` ) are more clearly visible, (b) it can be "generalized".  For example the **Normal distribution** can be a **Bernoulli distribution** (for binary data), or a **Poisson distribution** for count data, etc. 

--

3. `\(\alpha+\beta X_i\)` is the **predictor**, or the "modeled" portion.  There can be any number of variables in the **predictor** and they can have different powers, so: `$$Y_i \sim {\cal N}(\alpha + \beta X_i + \gamma Z_i + \delta X_i^2 + \nu X_i Z_i, \sigma )$$` is also a **linear** model. 

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false,
"highlightLines": true,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
